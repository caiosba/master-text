\select@language {english}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Fiducial marker used to represent a three-dimensional model over it \cite {artoolkit}}}{2}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Global vision}}{3}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The augmented reality is localized between the extremes of the reality-virtuality continuum}}{7}
\contentsline {figure}{\numberline {2.2}{\ignorespaces The typical pipeline of an augmented reality application \cite {gallo11}}}{8}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Immersive augmented reality}}{8}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Non-immersive augmented reality}}{9}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Example of fiducial marker used by medical applications}}{10}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Example of fiducial marker for motion capture}}{10}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Images of a chessboard being held at various orientations (left) provide enough information to completely solve for the locations of those images in global coordinates (relative to the camera) and the camera intrinsics \cite {bradski2008learning}}}{14}
\contentsline {figure}{\numberline {2.8}{\ignorespaces A multi-resolution pyramid with three levels \cite {michele}}}{21}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Pyramid Lucas-Kanade optical flow: running optical flow at the top of the pyramid first mitigates the problems caused by violating our assumptions of small and coherent motion; the motion estimate from the preceding level is taken as the starting point for estimating motion at the next layer down \cite {bradski2008learning}}}{25}
\contentsline {figure}{\numberline {2.10}{\ignorespaces The same input image being used for features identification by Shi-Tomasi algorithm (red dots) and by Harris Corner Detector (green dots)}}{25}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces ARBioMed running, with three fiducial markers \cite {arbiomed}}}{28}
\contentsline {figure}{\numberline {3.2}{\ignorespaces User under augmented virtual therapy \cite {fisio}}}{28}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Patient with stroke performing an exercise to reach melody boxes \cite {stroke}}}{29}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Difference between using a single Kinect and more than one Kinects}}{31}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Three Kinect devices being used for a full scan of the human body with minimum overlapping \cite {tong}}}{32}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Calibrating Kinect using toolbox from \cite {herrera}}}{33}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Vuzix Wrap 920AR augmented reality glasses}}{36}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Augmented reality pipeline}}{37}
\contentsline {figure}{\numberline {4.3}{\ignorespaces High level representation of the augmented reality environment implementation}}{38}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Experimental environment arranged for the implementation}}{39}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Experimental environment arranged for the implementation with each component identified by a number}}{40}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Distances between each component on the experimental environment}}{41}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Capturable movements from glasses \cite {vuzixsdk}}}{42}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Coordinates system of augmented reality glasses' tracker \cite {vuzixsdk}}}{42}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Glasses calibration log}}{44}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Glasses' tracker controlling a virtual cube in order to check its accuracy}}{44}
\contentsline {figure}{\numberline {4.11}{\ignorespaces RGB map and depth map with no matching between them}}{45}
\contentsline {figure}{\numberline {4.12}{\ignorespaces RGB map and depth map with depth registration enabled}}{46}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Two Kinects in action: above, the real configuration (two Kinects capturing the same object) and below, the virtual image combined}}{47}
\contentsline {figure}{\numberline {4.14}{\ignorespaces How OpenCV's cornerSubPix function works \cite {opencvfd}}}{48}
\contentsline {figure}{\numberline {4.15}{\ignorespaces Calibration process and result}}{50}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Chessboard recognized by both Kinect's camera and glasses' camera}}}{50}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Reconstructed model from Kinect}}}{50}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Model captured by Kinect transformed to glasses' camera space according to the calibration between them}}}{50}
\contentsline {figure}{\numberline {4.16}{\ignorespaces Cross-over connection between two computers}}{52}
\contentsline {figure}{\numberline {4.17}{\ignorespaces UDP and TCP protocols}}{53}
\addvspace {10\p@ }
\addvspace {10\p@ }
